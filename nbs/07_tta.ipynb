{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp tta\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Time Augmentation\n",
    "\n",
    "> Code adapted from https://github.com/qubvel/ttach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *\n",
    "from fastai.torch_core import TensorImage, TensorMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import itertools\n",
    "from functools import partial\n",
    "from typing import List, Optional, Union\n",
    "from fastcore.foundation import store_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def rot90(x, k=1):\n",
    "    \"rotate batch of images by 90 degrees k times\"\n",
    "    return torch.rot90(x, k, (2, 3))\n",
    "\n",
    "def hflip(x):\n",
    "    \"flip batch of images horizontally\"\n",
    "    return x.flip(3)\n",
    "\n",
    "def vflip(x):\n",
    "    \"flip batch of images vertically\"\n",
    "    return x.flip(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseTransform:\n",
    "    identity_param = None\n",
    "    def __init__(self, pname: str, params: Union[list, tuple]): store_attr()\n",
    "\n",
    "class Chain:\n",
    "    def __init__(self, functions: List[callable]):\n",
    "        self.functions = functions or []\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for f in self.functions:\n",
    "            x = f(x)\n",
    "        return x\n",
    "\n",
    "class Transformer:\n",
    "    def __init__(self, image_pipeline: Chain, mask_pipeline: Chain):\n",
    "        store_attr()\n",
    "        \n",
    "    def augment_image(self, image):\n",
    "        return self.image_pipeline(image)\n",
    "\n",
    "    def deaugment_mask(self, mask):\n",
    "        return self.mask_pipeline(mask)\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, aug_transforms: List[BaseTransform]):\n",
    "        store_attr()\n",
    "        self.aug_transform_parameters = list(itertools.product(*[t.params for t in self.aug_transforms]))\n",
    "        self.deaug_transforms = aug_transforms[::-1]\n",
    "        self.deaug_transform_parameters = [p[::-1] for p in self.aug_transform_parameters]\n",
    "\n",
    "    def __iter__(self) -> Transformer:\n",
    "        for aug_params, deaug_params in zip(self.aug_transform_parameters, self.deaug_transform_parameters):\n",
    "            image_aug_chain = Chain([partial(t.apply_aug_image, **{t.pname: p})\n",
    "                                     for t, p in zip(self.aug_transforms, aug_params)])\n",
    "            mask_deaug_chain = Chain([partial(t.apply_deaug_mask, **{t.pname: p})\n",
    "                                      for t, p in zip(self.deaug_transforms, deaug_params)])\n",
    "            yield Transformer(image_pipeline=image_aug_chain, mask_pipeline=mask_deaug_chain)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.aug_transform_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "class Merger:\n",
    "    def __init__(self):\n",
    "        self.output = []\n",
    "        \n",
    "    def append(self, x):\n",
    "        self.output.append(torch.as_tensor(x))\n",
    "            \n",
    "    def result(self, type='mean'):\n",
    "        s = torch.stack(self.output)\n",
    "        if type == 'max':\n",
    "            result = torch.max(s, dim=0)[0]\n",
    "        \n",
    "        elif type == 'mean':\n",
    "            result = torch.mean(s, dim=0)\n",
    "        \n",
    "        elif type == 'std':\n",
    "            result = torch.std(s, dim=0)\n",
    "    \n",
    "        elif type == 'uncertainty':\n",
    "            # adapted from https://github.com/ykwon0407/UQ_BNN/blob/master/retina/utils.py\n",
    "            aleatoric_uncertainty = torch.mean(s * (1 - s), dim=0)\n",
    "            epistemic_uncertainty = torch.mean(s**2, dim=0) - torch.mean(s, dim=0)**2\n",
    "            result = epistemic_uncertainty + aleatoric_uncertainty\n",
    "        \n",
    "        elif type == 'aleatoric_uncertainty':\n",
    "            result = torch.mean(s * (1 - s), dim=0)\n",
    "            \n",
    "        elif type == 'epistemic_uncertainty':\n",
    "            result = torch.mean(s**2, dim=0) - torch.mean(s, dim=0)**2\n",
    "            \n",
    "        elif type == 'entropy':\n",
    "            result = -torch.sum(s * torch.log(s), dim=0)\n",
    "    \n",
    "        else:\n",
    "            raise ValueError('Not correct merge type `{}`.'.format(self.type))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = TensorImage(torch.randn(4, 2, 356, 356))\n",
    "for t in ['mean', 'max', 'std', 'uncertainty', 'entropy', 'aleatoric_uncertainty', 'epistemic_uncertainty']:\n",
    "    m = Merger()\n",
    "    for _ in range(10): m.append(imgs)    \n",
    "    test_eq(imgs.shape, m.result(t).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HorizontalFlip(BaseTransform):\n",
    "    \"Flip images horizontally (left->right)\"\n",
    "    identity_param = False\n",
    "    def __init__(self):\n",
    "        super().__init__(\"apply\", [False, True])\n",
    "\n",
    "    def apply_aug_image(self, image, apply=False, **kwargs):\n",
    "        if apply: image = hflip(image)\n",
    "        return image\n",
    "\n",
    "    def apply_deaug_mask(self, mask, apply=False, **kwargs):\n",
    "        if apply: mask = hflip(mask)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = HorizontalFlip()\n",
    "aug = t.apply_aug_image(imgs)\n",
    "deaug = t.apply_deaug_mask(aug)\n",
    "test_eq(imgs, deaug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VerticalFlip(BaseTransform):\n",
    "    \"Flip images vertically (up->down)\"\n",
    "    identity_param = False\n",
    "    def __init__(self):\n",
    "        super().__init__(\"apply\", [False, True])\n",
    "\n",
    "    def apply_aug_image(self, image, apply=False, **kwargs):\n",
    "        if apply: image = vflip(image)\n",
    "        return image\n",
    "\n",
    "    def apply_deaug_mask(self, mask, apply=False, **kwargs):\n",
    "        if apply: mask = vflip(mask)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = VerticalFlip()\n",
    "aug = t.apply_aug_image(imgs)\n",
    "deaug = t.apply_deaug_mask(aug)\n",
    "test_eq(imgs, deaug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Rotate90(BaseTransform):\n",
    "    \"Rotate images 0/90/180/270 degrees (`angles`)\"\n",
    "    identity_param = 0\n",
    "    def __init__(self, angles: List[int]):\n",
    "        if self.identity_param not in angles:\n",
    "            angles = [self.identity_param] + list(angles)\n",
    "        super().__init__(\"angle\", angles)\n",
    "\n",
    "    def apply_aug_image(self, image, angle=0, **kwargs):\n",
    "        k = angle // 90 if angle >= 0 else (angle + 360) // 90\n",
    "        return rot90(image, k)\n",
    "\n",
    "    def apply_deaug_mask(self, mask, angle=0, **kwargs):\n",
    "        return self.apply_aug_image(mask, -angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Rotate90([180])\n",
    "aug = t.apply_aug_image(imgs)\n",
    "deaug = t.apply_deaug_mask(aug)\n",
    "test_eq(imgs, deaug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms=[HorizontalFlip(),VerticalFlip(), Rotate90(angles=[90,180,270])]\n",
    "c = Compose(tfms)\n",
    "m = Merger()\n",
    "for t in c:\n",
    "    aug = t.augment_image(imgs)\n",
    "    deaug = t.deaugment_mask(aug)\n",
    "    test_eq(imgs, deaug)\n",
    "    m.append(deaug)\n",
    "test_close(imgs, m.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
