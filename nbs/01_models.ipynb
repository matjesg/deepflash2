{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Pytorch segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#architectures-\n",
    "ARCHITECTURES =  ['Unet', 'UnetPlusPlus', 'FPN', 'PAN', 'PSPNet', 'Linknet', 'DeepLabV3', 'DeepLabV3Plus'] #'MAnet',\n",
    "\n",
    "# https://github.com/qubvel/segmentation_models.pytorch#encoders-\n",
    "ENCODERS = [*smp.encoders.encoders.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenation Models Pytorch Integration\n",
    "\n",
    "From the website: \n",
    "\n",
    "- High level API (just two lines to create a neural network)\n",
    "- 9 models architectures for binary and multi class segmentation (including legendary Unet)\n",
    "- 104 available encoders\n",
    "- All encoders have pre-trained weights for faster and better convergence\n",
    "\n",
    "See https://github.com/qubvel/segmentation_models.pytorch for API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_pretrained_options(encoder_name):\n",
    "    'Return available options for pretrained weights for a given encoder'\n",
    "    options = smp.encoders.encoders[encoder_name]['pretrained_settings'].keys()\n",
    "    return [*options, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def create_smp_model(arch, **kwargs):\n",
    "    'Create segmentation_models_pytorch model'\n",
    "    \n",
    "    assert arch in ARCHITECTURES, f'Select one of {ARCHITECTURES}'\n",
    "        \n",
    "    if arch==\"Unet\": model =  smp.Unet(**kwargs)\n",
    "    elif arch==\"UnetPlusPlus\": model = smp.UnetPlusPlus(**kwargs)\n",
    "    elif arch==\"MAnet\":model = smp.MAnet(**kwargs)\n",
    "    elif arch==\"FPN\": model = smp.FPN(**kwargs)\n",
    "    elif arch==\"PAN\": model = smp.PAN(**kwargs)\n",
    "    elif arch==\"PSPNet\": model = smp.PSPNet(**kwargs)\n",
    "    elif arch==\"Linknet\": model = smp.Linknet(**kwargs)\n",
    "    elif arch==\"DeepLabV3\": model = smp.DeepLabV3(**kwargs)\n",
    "    elif arch==\"DeepLabV3Plus\": model = smp.DeepLabV3Plus(**kwargs)\n",
    "    else: raise NotImplementedError\n",
    "    \n",
    "    setattr(model, 'kwargs', kwargs)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/anaconda3/envs/fastai2/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "bs = 2\n",
    "tile_shapes = [512] #1024\n",
    "in_channels = [1] #1,3,4\n",
    "classes = [2] # 2,5\n",
    "encoders = ENCODERS[1:2]#+ENCODERS[-1:]\n",
    "\n",
    "for ts in tile_shapes:\n",
    "    for in_c in in_channels:\n",
    "        for c in classes:\n",
    "            inp = torch.randn(bs, in_c, ts, ts)\n",
    "            out_shape = [bs, c, ts, ts]\n",
    "            for arch in ARCHITECTURES:\n",
    "                for encoder_name in encoders:\n",
    "                    model = create_smp_model(arch=arch, \n",
    "                                             encoder_name=encoder_name,\n",
    "                                             encoder_weights=None,\n",
    "                                             in_channels=in_c, \n",
    "                                             classes=c)\n",
    "                    out = model(inp)\n",
    "                    test_eq(out.shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_smp_model(model, arch, file,  stats=None, pickle_protocol=2):\n",
    "    'Save smp model, optionally including  stats'\n",
    "    state = model.state_dict()\n",
    "    save_dict = {'model': state, 'arch': arch, 'stats': stats, **model.kwargs}\n",
    "    torch.save(save_dict, file, pickle_protocol=pickle_protocol, _use_new_zipfile_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'Unet'\n",
    "file = 'tst.pth'\n",
    "stats = (1,1)\n",
    "kwargs = {'encoder_name': 'resnet34'}\n",
    "tst = create_smp_model(arch, **kwargs)\n",
    "save_smp_model(tst, arch, file, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_smp_model(file, device=None, strict=True, **kwargs):\n",
    "    'Loads smp model from file '\n",
    "    if isinstance(device, int): device = torch.device('cuda', device)\n",
    "    elif device is None: device = 'cpu'  \n",
    "    model_dict = torch.load(file, map_location=device)\n",
    "    state = model_dict.pop('model')    \n",
    "    stats = model_dict.pop('stats')    \n",
    "    model = create_smp_model(**model_dict)\n",
    "    model.load_state_dict(state, strict=strict)\n",
    "    return model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst2, stats2 = load_smp_model(file)\n",
    "for p1, p2 in zip(tst.parameters(), tst2.parameters()):\n",
    "    test_eq(p1.detach(), p2.detach())\n",
    "test_eq(stats, stats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_learner.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 02_data.ipynb.\n",
      "Converted 03_metrics.ipynb.\n",
      "Converted 05_losses.ipynb.\n",
      "Converted 06_utils.ipynb.\n",
      "Converted 07_tta.ipynb.\n",
      "Converted 08_gui.ipynb.\n",
      "Converted 09_gt.ipynb.\n",
      "Converted add_information.ipynb.\n",
      "Converted deepflash2.ipynb.\n",
      "Converted gt_estimation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted model_library.ipynb.\n",
      "Converted predict.ipynb.\n",
      "Converted train.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai2",
   "language": "python",
   "name": "fastai2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
