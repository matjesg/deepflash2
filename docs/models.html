---

title: Models


keywords: fastai
sidebar: home_sidebar

summary: "Pytorch segmentation models."
description: "Pytorch segmentation models."
nb_path: "nbs/01_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev</span> <span class="kn">import</span> <span class="o">*</span>
<span class="o">%</span><span class="k">nbdev_default_export</span> models
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Cells will be exported to deepflash2.models,
unless a different module is specified after an export flag: `%nbdev_export special.module`
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_hide</span>
<span class="kn">from</span> <span class="nn">nbdev.showdoc</span> <span class="kn">import</span> <span class="o">*</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">urllib</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="U-Net-models">U-Net models<a class="anchor-link" href="#U-Net-models"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Pytorch implementation adapted from <a href="https://github.com/jvanvugt/pytorch-unet">https://github.com/jvanvugt/pytorch-unet</a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="k">class</span> <span class="nc">UNetConvBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">neg_slope</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UNetConvBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">block</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">dropout</span><span class="o">&gt;</span><span class="mf">0.</span><span class="p">:</span>
            <span class="n">block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
        <span class="n">block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">padding</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
            <span class="n">block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">))</span>
        <span class="n">block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="n">neg_slope</span><span class="p">))</span>


        <span class="n">block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">padding</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
            <span class="n">block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">))</span>
        <span class="n">block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="n">neg_slope</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">block</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="k">class</span> <span class="nc">UNetUpBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">up_mode</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">neg_slope</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UNetUpBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">up_block</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">dropout</span><span class="o">&gt;</span><span class="mf">0.</span><span class="p">:</span>
            <span class="n">up_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">up_mode</span> <span class="o">==</span> <span class="s1">&#39;upconv&#39;</span><span class="p">:</span>
            <span class="n">up_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">up_mode</span> <span class="o">==</span> <span class="s1">&#39;upsample&#39;</span><span class="p">:</span>
            <span class="n">up_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">up_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
            <span class="n">up_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_size</span><span class="p">))</span>
        <span class="n">up_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="n">neg_slope</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">up_block</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span> <span class="o">=</span> <span class="n">UNetConvBlock</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">center_crop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">target_size</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">layer_height</span><span class="p">,</span> <span class="n">layer_width</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">diff_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_height</span> <span class="o">-</span> <span class="n">target_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">diff_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_width</span> <span class="o">-</span> <span class="n">target_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">layer</span><span class="p">[</span>
            <span class="p">:,</span> <span class="p">:,</span> <span class="n">diff_y</span> <span class="p">:</span> <span class="p">(</span><span class="n">diff_y</span> <span class="o">+</span> <span class="n">target_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">diff_x</span> <span class="p">:</span> <span class="p">(</span><span class="n">diff_x</span> <span class="o">+</span> <span class="n">target_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">bridge</span><span class="p">):</span>
        <span class="n">up</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">crop1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_crop</span><span class="p">(</span><span class="n">bridge</span><span class="p">,</span> <span class="n">up</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">up</span><span class="p">,</span> <span class="n">crop1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="k">class</span> <span class="nc">UNet2D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s2">&quot;Pytorch U-Net Implementation&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">wf</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
        <span class="n">neg_slope</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
        <span class="n">up_mode</span><span class="o">=</span><span class="s1">&#39;upconv&#39;</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">up_mode</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;upconv&#39;</span><span class="p">,</span> <span class="s1">&#39;upsample&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">depth</span>
        <span class="n">prev_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_path</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                <span class="n">bn</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">bn</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">dropout</span><span class="o">&gt;</span><span class="mf">0.</span><span class="p">:</span>
                <span class="n">do</span> <span class="o">=</span> <span class="n">dropout</span> <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">2</span> <span class="k">else</span> <span class="mf">0.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">do</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down_path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">UNetConvBlock</span><span class="p">(</span><span class="n">prev_channels</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">wf</span> <span class="o">+</span> <span class="n">i</span><span class="p">),</span> <span class="n">padding</span><span class="p">,</span>
                              <span class="n">batch_norm</span><span class="o">=</span><span class="n">bn</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">do</span><span class="p">,</span><span class="n">neg_slope</span><span class="o">=</span><span class="n">neg_slope</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">prev_channels</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">wf</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">up_path</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                <span class="n">bn</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">0</span> <span class="k">else</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">bn</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">dropout</span><span class="o">&gt;</span><span class="mf">0.</span><span class="p">:</span>
                <span class="n">do</span> <span class="o">=</span> <span class="n">dropout</span> <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">2</span> <span class="k">else</span> <span class="mf">0.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">do</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up_path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">UNetUpBlock</span><span class="p">(</span><span class="n">prev_channels</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">wf</span> <span class="o">+</span> <span class="n">i</span><span class="p">),</span> <span class="n">up_mode</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
                            <span class="n">batch_norm</span><span class="o">=</span><span class="n">bn</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">do</span><span class="p">,</span> <span class="n">neg_slope</span><span class="o">=</span><span class="n">neg_slope</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">prev_channels</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">wf</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">prev_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize layer weights&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">blocks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">down</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">down_path</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">down</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">down_path</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">up</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">up_path</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">up</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">blocks</span><span class="p">[</span><span class="o">-</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">last</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Args</strong>:\
<code>in_channels</code> (int): the number of input channels.\
<code>n_classes</code> (int): the number of output channels. \
<code>depth</code> (int): depth of the network.\
<code>wf</code> (int): number of filters in the first layer is 2^wf
<code>padding</code> (bool): if True, apply padding such that the input shape is the same as the output. This may introduce artifacts\
<code>batch_norm</code> (bool): Use BatchNorm after layers with an activation function\
<code>up_mode</code> (str): one of 'upconv' or 'upsample'. 'upconv' will use transposed convolutions for learned upsampling. 'upsample' will use bilinear upsampling.\
<code>neg_slope</code>(float): Controls the angle of the negative slope for LeakyReLU. Standard ReLU if set to 0.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="n">_MODEL_BASE_URL</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/matjesg/deepflash2/releases/download/model_library/&#39;</span>
<span class="k">def</span> <span class="nf">_load_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">progress</span><span class="p">):</span>
    <span class="s2">&quot;Loads pretrained model weights&quot;</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">_MODEL_BASE_URL</span><span class="o">+</span><span class="n">dataset</span><span class="o">+</span><span class="s1">&#39;.pth&#39;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="n">progress</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error: No weights available for model trained on </span><span class="si">{</span><span class="n">dataset</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s1">&#39;last.weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s1">&#39;last.weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No pretrained weights for </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s1">&#39;last.weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> classes in final layer.&quot;</span><span class="p">)</span>
        <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;last.bias&#39;</span><span class="p">)</span>
        <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;last.weight&#39;</span><span class="p">)</span>
        

    <span class="c1"># TODO Better handle different number of input channels</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1">#print(f&quot;Loaded model weights trained on {dataset}.&quot;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="U-Net-architectures">U-Net architectures<a class="anchor-link" href="#U-Net-architectures"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Original U-Net architecture based on <em>Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. "U-net: Convolutional networks for biomedical image segmentation." International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015.</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="k">def</span> <span class="nf">unet_ronneberger2015</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span> <span class="p">,</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;wue1_cFOS&#39;</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="s2">&quot;Original U-Net architecture based on Ronnberger et al. (2015)&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">UNet2D</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
                   <span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">wf</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                   <span class="n">neg_slope</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">up_mode</span><span class="o">=</span><span class="s1">&#39;upconv&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="n">_load_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">progress</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>U-Net architecture based on <em>Falk, Thorsten, et al. "U-Net: deep learning for cell counting, detection, and morphometry." Nature methods 16.1 (2019): 67-70.</em></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="k">def</span> <span class="nf">unet_falk2019</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span> <span class="p">,</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;wue1_cFOS&#39;</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="s2">&quot;U-Net architecture based on Falk et al. (2019)&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">UNet2D</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
               <span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">wf</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">neg_slope</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">up_mode</span><span class="o">=</span><span class="s1">&#39;upconv&#39;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="n">_load_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">progress</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>U-Net model optimized for deepflash2</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="k">def</span> <span class="nf">unet_deepflash2</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span> <span class="p">,</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;wue_cFOS&#39;</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=.</span><span class="mi">5</span><span class="p">):</span>
    <span class="s2">&quot;U-Net model optimized for deepflash2&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">UNet2D</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> 
                   <span class="n">depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">wf</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">neg_slope</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">up_mode</span><span class="o">=</span><span class="s1">&#39;upconv&#39;</span><span class="p">,</span> <span class="p">)</span>
    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="n">_load_pretrained</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">progress</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tst</span> <span class="o">=</span> <span class="n">unet_deepflash2</span><span class="p">()</span>
<span class="n">tst</span> <span class="o">=</span> <span class="n">unet_deepflash2</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tst</span> <span class="o">=</span> <span class="n">unet_deepflash2</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No pretrained weights for 3 classes in final layer.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_export</span>
<span class="k">def</span> <span class="nf">unet_custom</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span> <span class="p">,</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="s2">&quot;Customizable U-Net model. Customize via kwargs&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">UNet2D</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;No pretrained weights available for custom architecture.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">nbdev_hide</span>
<span class="kn">from</span> <span class="nn">nbdev.export</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">notebook2script</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted 00_learner.ipynb.
Converted 01_models.ipynb.
Converted 02_data.ipynb.
Converted 03_metrics.ipynb.
Converted 04_callbacks.ipynb.
Converted 05_losses.ipynb.
Converted 06_utils.ipynb.
Converted add_information.ipynb.
Converted gt_estimation.ipynb.
Converted index.ipynb.
Converted model_library.ipynb.
Converted predict.ipynb.
Converted train.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

